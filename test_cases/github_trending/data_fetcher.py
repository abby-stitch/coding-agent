# github_fetcher.py â€”â€” GitHub Trending æ•°æ®æŠ“å–å™¨ï¼ˆData Agentï¼‰
import json
from datetime import datetime
from pathlib import Path
import urllib.request
from urllib.parse import urljoin
from bs4 import BeautifulSoup

# é…ç½®ï¼šæŠ“å– Python é¡¹ç›®çš„ä»Šæ—¥ trending
LANGUAGE = "python"
TIME_WINDOW = "daily"  # or "weekly"
MAX_RESULTS = 10

def fetch_github_trending():
    print(f"  â†’ è·å– GitHub {LANGUAGE} ä»Šæ—¥ trending é¡¹ç›®...")
    base_url = "https://github.com/trending"
    if LANGUAGE:
        url = f"{base_url}/{LANGUAGE}?since={TIME_WINDOW}"
    else:
        url = f"{urljoin(base_url, '')}?since={TIME_WINDOW}"

    # è®¾ç½® User-Agent é¿å…è¢«æ‹’
    req = urllib.request.Request(
        url,
        headers={
            "User-Agent": "Mozilla/5.0 (compatible; ArxivAgent/1.0; +https://github.com/yourname)"
        }
    )

    try:
        with urllib.request.urlopen(req) as response:
            html = response.read().decode("utf-8")
        projects = parse_github_trending(html)
        print(f"    âœ… æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®")
        return projects[:MAX_RESULTS]
    except Exception as e:
        print(f"    âš ï¸ å¤±è´¥: {e}")
        return []

def parse_github_trending(html):
    soup = BeautifulSoup(html, "html.parser")
    projects = []

    for article in soup.select("article.Box-row"):
        # é¡¹ç›®åï¼ˆå¸¦ ownerï¼‰
        name_elem = article.select_one("h2 a")
        if not name_elem:
            continue
        full_name = name_elem.get("href").strip("/")
        owner, repo = full_name.split("/", 1)

        # æè¿°
        desc_elem = article.select_one("p.col-9")
        description = desc_elem.get_text(strip=True) if desc_elem else ""

        # è¯­è¨€
        lang_elem = article.select_one("span[itemprop='programmingLanguage']")
        language = lang_elem.get_text(strip=True) if lang_elem else LANGUAGE or "Unknown"

        # æ˜Ÿæ ‡æ•° & å¢é•¿
        stars = ""
        forks = ""
        for span in article.select("span.d-inline-block.float-sm-right"):
            text = span.get_text(strip=True)
            if "stars" in text:
                stars = text.replace("stars today", "").replace("star today", "").strip()
            elif "forks" in text:
                forks = text

        # é¡¹ç›®é“¾æ¥
        project_url = f"https://github.com/{full_name}"

        projects.append({
            "id": full_name,  # e.g., "microsoft/vscode"
            "owner": owner,
            "repo": repo,
            "description": description,
            "language": language,
            "stars_today": stars,
            "forks": forks,
            "url": project_url,
            "fetch_date": datetime.utcnow().strftime('%Y-%m-%d')
        })

    return projects

def run_data_agent():
    """
    Data Agent ä¸»å…¥å£ï¼šæŠ“å– GitHub Trending é¡¹ç›®ï¼Œè¾“å‡ºä¸º outputs/data.jsonã€‚
    ä¸ä½¿ç”¨ LLMï¼Œç¡®ä¿æ•°æ®çœŸå®æ€§ã€‚
    """
    print("  â†’ å¼€å§‹ä» GitHub æŠ“å– trending é¡¹ç›®...")
    projects = fetch_github_trending()

    if not projects:
        print("    âš ï¸ æœªè·å–åˆ°ä»»ä½•é¡¹ç›®ï¼Œç”Ÿæˆç¤ºä¾‹æ•°æ®")
        projects = [{
            "id": "example/hello-world",
            "owner": "example",
            "repo": "hello-world",
            "description": "A sample project for testing",
            "language": "Python",
            "stars_today": "123",
            "forks": "45",
            "url": "https://github.com/example/hello-world",
            "fetch_date": datetime.utcnow().strftime('%Y-%m-%d')
        }]

    # âœ… è·¯å¾„ï¼šå›åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆä¸¤çº§ parentï¼‰
    script_dir = Path(__file__).resolve().parent
    project_root = script_dir.parent.parent
    output_dir = project_root / "outputs"
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / "data.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(projects, f, ensure_ascii=False, indent=2)

    print(f"  ğŸ‰ å…±ä¿å­˜ {len(projects)} ä¸ªé¡¹ç›®åˆ° {output_path.resolve()}")

if __name__ == "__main__":
    run_data_agent()