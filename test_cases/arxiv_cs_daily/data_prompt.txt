你是一个专业的数据工程师，请编写一个完整的 Python 脚本，从 arXiv 官方 RSS 接口抓取真实的计算机科学论文数据。

具体要求：
- 抓取四个分类：cs.AI、cs.TH、cs.CV、cs.LG
- 每个分类获取最近提交的 2 篇论文（共 8 篇）
- 每篇论文必须包含以下字段：
  * id: 论文 ID，格式如 "2412.12345"
  * title: 论文标题（字符串）
  * authors: 作者列表（字符串列表）
  * category: 分类标签（如 "cs.AI"）
  * submit_date: 提交日期，格式为 "YYYY-MM-DD"
  * pdf_url: PDF 链接，格式为 "https://arxiv.org/pdf/{id}.pdf"

数据来源：
- 使用 arXiv RSS 接口：http://export.arxiv.org/rss/{category}
- 使用 feedparser 库解析 RSS

输出要求：
- 脚本最后必须执行：print(json.dumps(papers, indent=2))
- 只输出可直接运行的 Python 代码
- 不要任何解释、注释、Markdown
- 处理异常，确保脚本能正常退出

现在请直接输出完整的 Python 脚本。